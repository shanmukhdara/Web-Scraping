{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "103684ae",
   "metadata": {},
   "source": [
    "# Ebay web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c095a7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#please make sure you have the below libraries, if now install before running the below code\n",
    "#importing all the required packages\n",
    "import requests\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup\n",
    "import itertools\n",
    "import time \n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61364e00",
   "metadata": {},
   "source": [
    "## Task 1 \n",
    "pull the spotlight deal from the eBay website and print the product with both the regular and discounted price\n",
    "\n",
    "* This code is based on HTML and CSS feature extraction, and it may not work if the HTML structure changes\n",
    "* just for reference only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53935916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product in spotlight is:  1/2ct Diamond & Blue Sapphire Heart Pendant 14K White Gold\n",
      "Reduced price of the product: $129.24\n",
      "Actual Price of the product: $439.96 \n"
     ]
    }
   ],
   "source": [
    "#Url to be accessed\n",
    "url = \"https://www.ebay.com/deals\"\n",
    "\n",
    "\n",
    "#passign headers while accessing the webpage just to mimic human behavior \n",
    "#otherwise websites understands us to be a bot and returns a bot error\n",
    "\n",
    "HEADERS = {'User-Agent':\n",
    "           'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36',\n",
    "                           'Accept-Language': 'en-US, en;q=0.5'}\n",
    "\n",
    "#requesting data from url -- get request \n",
    "get_data = requests.get(url, headers= HEADERS)\n",
    "\n",
    "#converting response from website to a lxml format to access it easily\n",
    "soup = BeautifulSoup(get_data.text, 'lxml')\n",
    "\n",
    "#filtering the spotlight product from the webpage\n",
    "product_spotlight = soup.findAll('div', class_=\"ebayui-dne-summary-card card ebayui-dne-item-featured-card--topDeals ebayui-dne-featured-with-carousel\")\n",
    "\n",
    "#filtering out the name and price of the spotlight item\n",
    "#converting back the spotlight item into a xml object to access it easily\n",
    "product_spotlight_soup = BeautifulSoup(str(product_spotlight), 'lxml')\n",
    "\n",
    "#title of the product\n",
    "product_title = product_spotlight_soup.findAll('h3', class_='dne-itemtile-title ellipse-3')\n",
    "print(\"Product in spotlight is: \", product_title[0].text)\n",
    "\n",
    "#Current and the previous prices\n",
    "print(\"Reduced price of the product:\", product_spotlight_soup.findAll('span',class_=\"first\")[0].text)\n",
    "try:\n",
    "    print(\"Actual Price of the product:\", product_spotlight_soup.findAll('span',class_=\"itemtile-price-strikethrough\")[0].text)\n",
    "except:\n",
    "    print(\"Actual Price of the product: Actual price same as reduced price\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602911c2",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "Scrape the first 10 product pages on ebay auction of \"lg phone\", store them to local files, read them back and scrape all the products and corresponding links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e1958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the required packages\n",
    "import requests\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup\n",
    "import itertools\n",
    "import time \n",
    "import random\n",
    "#Url to be accessed\n",
    "url = \"https://www.ebay.com/sch/i.html?_nkw=lg+phone&LH_Auction=1\"\n",
    "\n",
    "#passign headers while accessing the webpage just to mimic human behavior\n",
    "HEADERS = {'User-Agent':\n",
    "           'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36',\n",
    "                           'Accept-Language': 'en-US, en;q=0.5'}\n",
    "#requesting data from url\n",
    "for i in range(1,11):\n",
    "    get_data = requests.get(url+\"&_pgn=\"+str(i), headers= HEADERS)\n",
    "    #converting response from website to a lxml format to access it easily\n",
    "    soup = BeautifulSoup(get_data.text, 'html')\n",
    "\n",
    "    ftp = open(\"ebay_lg_phone\"+str(i)+\".html\",\"w+\")\n",
    "    ftp.write(str(soup.prettify()))\n",
    "    ftp.close()\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb7621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets real all those files\n",
    "for i in range(1,11):\n",
    "    ftp = open(\"ebay_lg_phone\"+str(i)+\".html\",\"r\")\n",
    "    content = ftp.read()\n",
    "    ftp.close()\n",
    "    # convert them into a BS object\n",
    "    soup = BeautifulSoup(get_data.text, 'lxml')\n",
    "    products = soup.findAll('div', class_='s-item__wrapper clearfix')\n",
    "    #lets print all the required items\n",
    "    for i in products[1:]:\n",
    "        # title of the product\n",
    "        print(i.findAll(\"h3\",class_='s-item__title')[0].text)\n",
    "        #no of bids \n",
    "        print(i.findAll(\"span\",class_='s-item__bids s-item__bidCount')[0].text)\n",
    "        #link of the product\n",
    "        print(i.findAll(\"a\", class_='s-item__link')[0][\"href\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
